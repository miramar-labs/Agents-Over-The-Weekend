{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d3407",
   "metadata": {},
   "source": [
    "## API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your API keys in the .env file..\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY is not set\"\n",
    "assert os.getenv(\"LANGCHAIN_API_KEY\"), \"LANGCHAIN_API_KEY is not set\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afc5554",
   "metadata": {},
   "source": [
    "## Tracability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
    "\n",
    "tracer = LangChainTracer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade40bf",
   "metadata": {},
   "source": [
    "## System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "sp1=SystemMessage(content=\"\"\"Return a comma separated list of exactly 5 valid YouTube video IDs \n",
    "that are most relevant to the user's query.\n",
    "For example: 'id1,id2,id3,id4,id5'\"\"\")\n",
    "\n",
    "sp2=SystemMessage(content=\"Use the context below to answer the question.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafdf69b",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# create the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\", \n",
    "    temperature=0,\n",
    "    callbacks=[tracer]\n",
    "    )\n",
    "\n",
    "prompt_videos = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Return a comma separated list of exactly 5 valid YouTube video IDs that are most \n",
    "                  relevant to the user's query. \n",
    "                  For example: 'id1,id2,id3,id4,id5'\"\"\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "\n",
    "prompt_answer = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Use the context below to answer the question.\"),\n",
    "    (\"human\", \"{query}\\n\\nContext:\\n{context}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e72869",
   "metadata": {},
   "source": [
    "## Knowledgebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13401d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up any Embeddings/Vector DB's here\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = None  # Global FAISS store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1376eb6f",
   "metadata": {},
   "source": [
    "## Graph Nodes/Lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def step_get_video_ids(state):\n",
    "    query = state[\"query\"]\n",
    "    video_ids=[]\n",
    "    messages = prompt_videos.invoke({\"query\": query})\n",
    "    response = llm.invoke(messages).content\n",
    "    video_ids =response.split(',')\n",
    "    print(f\"Retrieved and filtered Video IDs: {video_ids}\")\n",
    "    return {\"query\": query, \"video_ids\": video_ids}\n",
    "\n",
    "def step_get_transcripts(state):\n",
    "    video_ids = state[\"video_ids\"]\n",
    "    docs = []\n",
    "    for vid in video_ids:\n",
    "        try:\n",
    "            parts = YouTubeTranscriptApi.get_transcript(vid)\n",
    "            text = \" \".join(p[\"text\"] for p in parts)\n",
    "            docs.append(Document(page_content=text, metadata={\"video_id\": vid}))\n",
    "        except Exception:\n",
    "            continue\n",
    "    if not docs:\n",
    "        print(\"Warning: No transcripts were retrieved for the given video IDs.\")\n",
    "    return {\"query\": state[\"query\"], \"documents\": docs}\n",
    "\n",
    "def step_embed_docs(state):\n",
    "    docs = state[\"documents\"]\n",
    "    if docs:\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        chunks = splitter.split_documents(docs)\n",
    "        global vectorstore\n",
    "        vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "    return {\"query\": state[\"query\"]}\n",
    "\n",
    "def step_rag_answer(state):\n",
    "    context=''\n",
    "    if vectorstore:\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "        results = retriever.invoke(state[\"query\"])\n",
    "        context = \"\\n\\n\".join(doc.page_content for doc in results)\n",
    "    messages = prompt_answer.invoke({\"query\": state[\"query\"], \"context\": context})\n",
    "    response = llm.invoke(messages).content\n",
    "    return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bae372",
   "metadata": {},
   "source": [
    "## Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb5e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up LangChain/LangGraph here\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph\n",
    "import operator\n",
    "\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    video_ids: List[str]\n",
    "    documents: List[Document]\n",
    "    answer: str\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"get_video_ids\", RunnableLambda(step_get_video_ids))\n",
    "graph.add_node(\"get_transcripts\", RunnableLambda(step_get_transcripts))\n",
    "graph.add_node(\"embed_docs\", RunnableLambda(step_embed_docs))\n",
    "graph.add_node(\"rag_answer\", RunnableLambda(step_rag_answer))\n",
    "\n",
    "graph.set_entry_point(\"get_video_ids\")\n",
    "graph.add_edge(\"get_video_ids\", \"get_transcripts\")\n",
    "graph.add_edge(\"get_transcripts\", \"embed_docs\")\n",
    "graph.add_edge(\"embed_docs\", \"rag_answer\")\n",
    "graph.set_finish_point(\"rag_answer\")\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f3b7cd",
   "metadata": {},
   "source": [
    "## The Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d036355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045f952",
   "metadata": {},
   "source": [
    "## Kick off the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028554be",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are quantum effects in biology?\"\n",
    "result = app.invoke({\"query\": query})\n",
    "print(\"ðŸ“¥ Final RAG Answer:\\n\")\n",
    "print(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aotw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
