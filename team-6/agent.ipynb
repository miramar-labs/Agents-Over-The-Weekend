{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503d3407",
   "metadata": {},
   "source": [
    "## API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your API keys in the .env file..\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY is not set\"\n",
    "assert os.getenv(\"LANGCHAIN_API_KEY\"), \"LANGCHAIN_API_KEY is not set\"\n",
    "assert os.getenv(\"YOUTUBE_API_KEY\"), \"YOUTUBE_API_KEY is not set\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afc5554",
   "metadata": {},
   "source": [
    "## Traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
    "\n",
    "tracer = LangChainTracer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade40bf",
   "metadata": {},
   "source": [
    "## System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "\n",
    "SysPrompt1=SystemMessage(content=\"\"\"Return a comma separated list of exactly 5 valid YouTube video IDs \n",
    "that are most relevant to the user's query.\n",
    "For example: 'id1,id2,id3,id4,id5'\"\"\")\n",
    "\n",
    "SysPrompt2=SystemMessagePromptTemplate.from_template(\n",
    "    template=\"Return the youtube transcript for the video with ID {video_id}\"\n",
    ")\n",
    "\n",
    "SysPrompt3=SystemMessage(content=\"Use the context below to answer the question.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b310465",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "\n",
    "def youtube_search(query, max_results=5):\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=os.getenv(\"YOUTUBE_API_KEY\"))\n",
    "    search_response = youtube.search().list(\n",
    "        q=query,\n",
    "        type=\"video\",\n",
    "        part=\"id,snippet\",\n",
    "        maxResults=max_results\n",
    "    ).execute()\n",
    "\n",
    "    results = []\n",
    "    for item in search_response[\"items\"]:\n",
    "        video_id = item[\"id\"][\"videoId\"]\n",
    "        title = item[\"snippet\"][\"title\"]\n",
    "        results.append({\"title\": title, \"video_id\": video_id})\n",
    "\n",
    "    return results\n",
    "\n",
    "youtube_search_tool = Tool.from_function(\n",
    "    func=youtube_search,\n",
    "    name=\"youtube_search\",\n",
    "    description=\"Search for ID's of youtube videos that are most relevant to a user's query\"\n",
    ")\n",
    "\n",
    "def fetch_youtube_transcript(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return \"\\n\".join([t['text'] for t in transcript])\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Error fetching transcript: {e}\"\n",
    "\n",
    "youtube_transcript_tool = Tool.from_function(\n",
    "    func=fetch_youtube_transcript,\n",
    "    name=\"fetch_youtube_transcript\",\n",
    "    description=\"Returns the full transcript of a YouTube video given its ID (e.g., 'xZX4KHrqwhM').\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafdf69b",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate,HumanMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# create the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\", \n",
    "    temperature=0,\n",
    "    callbacks=[tracer]\n",
    "    )\n",
    "\n",
    "# create the Agent with tools\n",
    "agent = initialize_agent(\n",
    "    tools=[youtube_search_tool, youtube_transcript_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,  # or AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "prompt_videos = ChatPromptTemplate.from_messages([\n",
    "    SysPrompt1,\n",
    "    HumanMessagePromptTemplate.from_template(template=\"{query}\")]\n",
    "    )\n",
    "\n",
    "prompt_video_transcript = ChatPromptTemplate.from_messages([\n",
    "    SysPrompt2, \n",
    "    HumanMessagePromptTemplate.from_template(template=\"{query}\")])\n",
    "\n",
    "prompt_answer = ChatPromptTemplate.from_messages([\n",
    "    SysPrompt3, \n",
    "    HumanMessagePromptTemplate.from_template(template=\"{query}\\n\\nContext:\\n{context}\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e72869",
   "metadata": {},
   "source": [
    "## Knowledgebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13401d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up any Embeddings/Vector DB's here\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = None  # Global FAISS store (lazy init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1376eb6f",
   "metadata": {},
   "source": [
    "## Graph Nodes/Lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def step_get_video_ids(state):\n",
    "    video_ids=[]\n",
    "    messages = prompt_videos.invoke({\"query\": state[\"query\"]})\n",
    "    response = agent.invoke(messages)\n",
    "    video_ids = response['output'].split(',')\n",
    "    print(f\"‚úÖ Retrieved and filtered Video IDs: {video_ids}\")\n",
    "    return {\"query\": state[\"query\"], \"video_ids\": video_ids}\n",
    "\n",
    "def step_get_transcripts(state):\n",
    "    docs = []\n",
    "    for vid in state[\"video_ids\"]:\n",
    "        try:\n",
    "            messages = prompt_video_transcript.invoke({\"query\": state[\"query\"], \"video_id\": vid})\n",
    "            response = agent.invoke(messages)\n",
    "            docs.append(Document(page_content=response['output'], metadata={\"video_id\": vid}))\n",
    "        except Exception:\n",
    "            print(\"‚ö†Ô∏è Warning: No transcript was retrieved for video {vid}.\")\n",
    "            continue\n",
    "    if not docs:\n",
    "        print(\"‚ö†Ô∏è Warning: No transcripts were retrieved for the given video IDs.\")\n",
    "    return {\"query\": state[\"query\"], \"documents\": docs}\n",
    "\n",
    "def step_embed_docs(state):\n",
    "    if state[\"documents\"]:\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        chunks = splitter.split_documents(state[\"documents\"])\n",
    "        global vectorstore\n",
    "        vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "    return {\"query\": state[\"query\"]}\n",
    "\n",
    "def step_rag_answer(state):\n",
    "    context=''\n",
    "    if vectorstore:\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "        results = retriever.invoke(state[\"query\"])\n",
    "        context = \"\\n\\n\".join(doc.page_content for doc in results)\n",
    "    messages = prompt_answer.invoke({\"query\": state[\"query\"], \"context\": context})\n",
    "    response = agent.invoke(messages)\n",
    "    return {\"answer\": response['output']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bae372",
   "metadata": {},
   "source": [
    "## Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb5e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up LangChain/LangGraph here\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph\n",
    "import operator\n",
    "\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    video_ids: List[str]\n",
    "    documents: List[Document]\n",
    "    answer: str\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"get_video_ids\", RunnableLambda(step_get_video_ids))\n",
    "graph.add_node(\"get_transcripts\", RunnableLambda(step_get_transcripts))\n",
    "graph.add_node(\"embed_docs\", RunnableLambda(step_embed_docs))\n",
    "graph.add_node(\"rag_answer\", RunnableLambda(step_rag_answer))\n",
    "\n",
    "graph.set_entry_point(\"get_video_ids\")\n",
    "graph.add_edge(\"get_video_ids\", \"get_transcripts\")\n",
    "graph.add_edge(\"get_transcripts\", \"embed_docs\")\n",
    "graph.add_edge(\"embed_docs\", \"rag_answer\")\n",
    "graph.set_finish_point(\"rag_answer\")\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f3b7cd",
   "metadata": {},
   "source": [
    "## The Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d036355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045f952",
   "metadata": {},
   "source": [
    "## Kick off the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028554be",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are quantum effects in biology?\"\n",
    "result = app.invoke({\"query\": query})\n",
    "print(\"üß† Final Agent Answer:\\n\")\n",
    "print(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aotw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
